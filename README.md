# Scraping Top 20 GitHub collections repositories 
This is a web scraping project created in python using jupyter notebook, and libraries such as Beautifulsoup4, pandas, re, and os.

Primary Agendas: 
1. Create a .csv file for the list of collections on the GitHub page in the format of | Title | Description | URL |
2. Create individual .csv files for all the repositories of each collection following this format:
|username | repo_name | repo_desc | stars | forks | programming language | repo_url |
